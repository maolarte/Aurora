{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pandas import DataFrame\n",
        "from pandas import Series\n",
        "from copy import deepcopy\n",
        "from datetime import datetime\n",
        "import json\n",
        "\n",
        "defaultMissingValue = 999999\n",
        "\n",
        "\n",
        "def loadLocalJsonDoc(filepath, dataProp=''):\n",
        "    \"\"\"\n",
        "    return deserialised json in dictionary\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    filepath: file location or buffer.\n",
        "    dataProp: (optional) specified property to access required data\n",
        "    \"\"\"\n",
        "    output = {}\n",
        "    with open(file=filepath, mode='r', encoding='utf-8') as f:\n",
        "        json_load = json.load(f)\n",
        "        if (dataProp):\n",
        "            output = json_load[dataProp]\n",
        "        else:\n",
        "            output = json_load\n",
        "    return output\n",
        "\n",
        "# Import dataset\n",
        "services = pd.read_csv(\n",
        "    'Aurora_OfficeRonda_2_-_latest_version_-_False_-_2023-10-04-16-15-49.csv', sep=';', index_col=False)\n",
        "\n",
        "# Fill  missing values\n",
        "services = services.fillna(defaultMissingValue)\n",
        "\n",
        "# rename variables\n",
        "newColumns = loadLocalJsonDoc(\"defaults/rename_columns.json\")\n",
        "\n",
        "services_carto = services.rename(columns=newColumns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {},
      "outputs": [],
      "source": [
        "def toUnixTimestamp(time, format:str = \"%d/%m/%Y\"):\n",
        "    start = datetime(1970, 1, 1)\n",
        "    target = datetime.strptime(time, format)\n",
        "    in_seconds = (target - start).total_seconds()\n",
        "    in_milliseconds = int(in_seconds) * 1000\n",
        "    return in_milliseconds\n",
        "\n",
        "def codifyServices(value: str, values_dict: dict[str, int], otherValue:str):\n",
        "    if(type(value) == float or type(value) == int):\n",
        "        return otherValue\n",
        "    raw_values = value.split(\" \")\n",
        "    output = []\n",
        "    for value in raw_values:\n",
        "        try:      \n",
        "            codedValue = values_dict[value]\n",
        "            output.append(str(codedValue) )\n",
        "        except Exception as e:\n",
        "            output.append(otherValue)\n",
        "            \n",
        "    return \"|\".join(output)\n",
        "\n",
        "def processColumn(dfColumn:Series, values_dict: dict[int, str], other_value: str):\n",
        "    reversed_values_dict = dict( [( x[1],x[0])  for x in values_dict.items()])\n",
        "    return dfColumn.apply(lambda x: codifyServices(x, reversed_values_dict, other_value))\n",
        "\n",
        "def processMultValueColumns(df: DataFrame, columnObjectsList: list[dict]):\n",
        "    \"\"\"\n",
        "    df: DataFrame object\n",
        "    columnsObjectsList: list of column object\n",
        "    columnObject: dictionary {\"target_column\": str, \"output_column\": str, values_dict: dict, other_value: str}\n",
        "\n",
        "    return DataFrame Object\n",
        "    \"\"\"\n",
        "    for columnObject in columnObjectsList:\n",
        "        try:\n",
        "            target_column = columnObject[\"target_column\"]\n",
        "            output_column = columnObject[\"output_column\"]\n",
        "            values_dict = columnObject[\"values_dict\"]\n",
        "            other_value = str(columnObject[\"other_value\"])\n",
        "            df[output_column] =  processColumn(df[target_column], values_dict, other_value)\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            continue\n",
        "    return df\n",
        "\n",
        "def exportToFile(df: DataFrame,fileType: str, exportName: str):\n",
        "    \"\"\" \n",
        "    df -> Pandas DataFrame object\n",
        "    fileType -> Either \"csv\" or \"json\"\n",
        "    exportName -> File location\n",
        "    \"\"\"\n",
        "    if(fileType == \"csv\"):\n",
        "        name = f\"{exportName}.csv\"\n",
        "        df.to_csv(name)\n",
        "        print (f\"data export to {name}\")\n",
        "    else:\n",
        "        name = f\"{exportName}.json\"\n",
        "        df.to_json(name, orient=\"records\")\n",
        "        print (f\"data export to {name}\")\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {},
      "outputs": [],
      "source": [
        "# parsing date field into unix timestamp\n",
        "services_carto[\"timeunix\"] = services_carto[\"fecha\"].apply(lambda x: toUnixTimestamp(time=x, format=\"%Y-%m-%d\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {},
      "outputs": [],
      "source": [
        "def codifyServices(value: str, values_dict: dict[str, int], otherValue:str):\n",
        "    if(type(value) == float or type(value) == int):\n",
        "        return otherValue\n",
        "    raw_values = value.split(\" \")\n",
        "    output = []\n",
        "    for value in raw_values:\n",
        "        try:      \n",
        "            codedValue = values_dict[value]\n",
        "            output.append(str(codedValue) )\n",
        "        except Exception as e:\n",
        "            output.append(otherValue)\n",
        "            \n",
        "    return \"|\".join(output)\n",
        "\n",
        "def processColumn(dfColumn:Series, values_dict: dict[int, str], other_value: str):\n",
        "    reversed_values_dict = dict( [( x[1],x[0])  for x in values_dict.items()])\n",
        "    return dfColumn.apply(lambda x: codifyServices(x, reversed_values_dict, other_value))\n",
        "\n",
        "def processMultValueColumns(df: DataFrame, columnObjectsList: list[dict]):\n",
        "    \"\"\"\n",
        "    df: DataFrame object\n",
        "    columnsObjectsList: list of column object\n",
        "    columnObject: dictionary {\"target_column\": str, \"output_column\": str, values_dict: dict, other_value: str}\n",
        "\n",
        "    return DataFrame Object\n",
        "    \"\"\"\n",
        "    for columnObject in columnObjectsList:\n",
        "        try:\n",
        "            target_column = columnObject[\"target_column\"]\n",
        "            output_column = columnObject[\"output_column\"]\n",
        "            values_dict = columnObject[\"values_dict\"]\n",
        "            other_value = str(columnObject[\"other_value\"])\n",
        "            df[output_column] =  processColumn(df[target_column], values_dict, other_value)\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            continue\n",
        "    return df\n",
        "\n",
        "def exportToFile(df: DataFrame,fileType: str, exportName: str):\n",
        "    \"\"\" \n",
        "    df -> Pandas DataFrame object\n",
        "    fileType -> Either \"csv\" or \"json\"\n",
        "    exportName -> File location\n",
        "    \"\"\"\n",
        "    if(fileType == \"csv\"):\n",
        "        name = f\"{exportName}.csv\"\n",
        "        df.to_csv(name)\n",
        "        print (f\"data export to {name}\")\n",
        "    else:\n",
        "        name = f\"{exportName}.json\"\n",
        "        df.to_json(name, orient=\"records\")\n",
        "        print (f\"data export to {name}\")\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {},
      "outputs": [],
      "source": [
        "# serv_tipo (separating by pipe symbol and categorized with number)\n",
        "codify_dict = loadLocalJsonDoc(\"defaults/codification_dict.json\")\n",
        "services_dict = codify_dict[\"services_dict\"]\n",
        "\n",
        "# re structure variable cuenta_con\n",
        "cuenta_con_dict = codify_dict[\"cuenta_con_dict\"] \n",
        "\n",
        "# re structure variable children services (cual_serv1)\n",
        "cual_serv1_dict = codify_dict[\"cual_serv1_dict\"] \n",
        "\n",
        "# re structure variable women services (cual_ser_2)\n",
        "cual_ser_2_dict = codify_dict[\"cual_ser_2_dict\"] \n",
        "\n",
        "# re structure variable data storage (almacenamientoregistros)\n",
        "registro_dict = codify_dict[\"registro_dict\"] \n",
        "\n",
        "# variable funding \n",
        "financ_dict = codify_dict[\"financ_dict\"] \n",
        "\n",
        "#  variable challenges\n",
        "reto_dict = codify_dict[\"reto_dict\"] \n",
        "\n",
        "# variable lenguages\n",
        "idio_dict = codify_dict[\"idio_dict\"] \n",
        "\n",
        "# variable medios\n",
        "medio_dict = codify_dict[\"medio_dict\"] \n",
        "\n",
        "values = [\n",
        "    {\n",
        "        \"target_column\": \"serv_tipo\",\n",
        "        \"output_column\": \"serv_tipo1\",\n",
        "        \"values_dict\": services_dict,\n",
        "        \"other_value\": defaultMissingValue\n",
        "    },\n",
        "    {\n",
        "        \"target_column\": \"cuenta_con\",\n",
        "        \"output_column\": \"cuenta_c_1\",\n",
        "        \"values_dict\": cuenta_con_dict,\n",
        "        \"other_value\": defaultMissingValue\n",
        "    },\n",
        "    {\n",
        "        \"target_column\": \"cual_serv1\",\n",
        "        \"output_column\": \"cual_ser_1\",\n",
        "        \"values_dict\": cual_serv1_dict,\n",
        "        \"other_value\": defaultMissingValue\n",
        "    },\n",
        "    {\n",
        "        \"target_column\": \"cual_ser_2\",\n",
        "        \"output_column\": \"cual_ser_3\",\n",
        "        \"values_dict\": cual_ser_2_dict,\n",
        "        \"other_value\": defaultMissingValue\n",
        "    },\n",
        "    {\n",
        "        \"target_column\": \"almacenamientoregistros\",\n",
        "        \"output_column\": \"almacenamientoregistros_\",\n",
        "        \"values_dict\": cual_ser_2_dict,\n",
        "        \"other_value\": defaultMissingValue\n",
        "    },\n",
        "    {\n",
        "        \"target_column\": \"financiamiento\",\n",
        "        \"output_column\": \"financb\",\n",
        "        \"values_dict\": financ_dict,\n",
        "        \"other_value\": defaultMissingValue\n",
        "    },\n",
        "    {\n",
        "        \"target_column\": \"princ_reto\",\n",
        "        \"output_column\": \"princ_re_1\",\n",
        "        \"values_dict\": reto_dict ,\n",
        "        \"other_value\": defaultMissingValue\n",
        "    },\n",
        "    {\n",
        "        \"target_column\": \"idioma_ent\",\n",
        "        \"output_column\": \"idioma_e_1\",\n",
        "        \"values_dict\": idio_dict ,\n",
        "        \"other_value\": defaultMissingValue\n",
        "    },\n",
        "    {\n",
        "        \"target_column\": \"medios_bri\",\n",
        "        \"output_column\": \"medios_b_1\",\n",
        "        \"values_dict\": medio_dict ,\n",
        "        \"other_value\": defaultMissingValue\n",
        "    },\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_df = processMultValueColumns(services_carto, values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data export to output.csv\n"
          ]
        }
      ],
      "source": [
        "exportToFile(output_df, \"csv\", \"output\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# daily report of surveys "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {},
      "outputs": [],
      "source": [
        "import datetime\n",
        "\n",
        "services.fecha = pd.to_datetime(services.fecha)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>fecha</th>\n",
              "      <th>2023-10-03</th>\n",
              "      <th>2023-10-04</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>encuesta</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>joseeduardoherrera</th>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>luisdavidcalderonpatino</th>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>luisricardosolermadrid</th>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mariaalejandraolartedelgado</th>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>otro</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "fecha                        2023-10-03  2023-10-04\n",
              "encuesta                                           \n",
              "joseeduardoherrera                  1.0         NaN\n",
              "luisdavidcalderonpatino             1.0         NaN\n",
              "luisricardosolermadrid              2.0         NaN\n",
              "mariaalejandraolartedelgado         3.0         NaN\n",
              "otro                                1.0         1.0"
            ]
          },
          "execution_count": 157,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# totals \n",
        "survey_counts = services.groupby('encuesta').organizacionprincipal.count().reset_index()\n",
        "survey_counts = survey_counts.rename(columns={\"organizacionprincipal\": \"total_encuestas\"})\n",
        "survey_counts\n",
        "\n",
        "# totals by organization\n",
        "unpivoted = services.groupby(['encuesta', 'fecha'])['pais'].count().reset_index()\n",
        "pivoted = unpivoted.pivot(\n",
        "    columns='fecha',\n",
        "    index= 'encuesta',\n",
        "    values='pais')\n",
        "pivoted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {},
      "outputs": [],
      "source": [
        "#capacity vs attentions\n",
        "services['servicios'] = services['servicios'].str.split(' ')\n",
        "prueba = services.explode('servicios')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {},
      "outputs": [],
      "source": [
        "prueba= prueba[['_coordenadas_latitude', \n",
        "                '_coordenadas_longitude', \n",
        "                'servicios', \n",
        "                'organizacionprincipal', \n",
        "                'organizacionimplementadora',\n",
        "                'pais',\n",
        "                'punto_reporte', \n",
        "                '_uuid',\n",
        "                'diarioalimentacionynutricion',\n",
        "                'ayeralimentacionynutricion',\n",
        "                'promalimentacionynutricion',\n",
        "                'diarioalojamientotemporal',\n",
        "                'ayeralojamientotemporal',\n",
        "                'promalojamientotemporal',\n",
        "                'diarioapoyooayudapsicosocial',\n",
        "                'ayerapoyooayudapsicosocial',\n",
        "                'promapoyooayudapsicosocial',\n",
        "                'diarioasesorialegal',\n",
        "                'ayerasesorialegal',\n",
        "                'promasesorialegal',\n",
        "                'diarioeducacion',\n",
        "                'ayereducacion',\n",
        "                'promeducacion',\n",
        "                'diarioserviciosproteccion', \n",
        "                'ayerserviciosproteccion',\n",
        "                'promserviciosproteccion',\n",
        "                'diariorestablecimientodecontactofamiliar',\n",
        "                'ayerrestablecimientodecontactofamiliar',\n",
        "                'promrestablecimientodecontactofamiliar',\n",
        "                'diariosaludprimerosauxiliosyatencionmedica',\n",
        "                'ayersaludprimerosauxiliosyatencionmedica',\n",
        "                'promsaludprimerosauxiliosyatencionmedica',\n",
        "                'diarioaguapotable',\n",
        "                'ayeraguapotable',\n",
        "                'promaguapotable',\n",
        "                'diariosaneamiento',\n",
        "                'ayersaneamiento',\n",
        "                'promsaneamiento',\n",
        "                'diariohigiene',\n",
        "                'ayerhigiene',\n",
        "                'promhigiene',\n",
        "                'diariotransportehumanitario',\n",
        "                'ayertransportehumanitario',\n",
        "                'promtransportehumanitario',\n",
        "                'diariotransferenciasmonetarias',\n",
        "                'ayertransferenciasmonetarias',\n",
        "                'promtransferenciasmonetarias',\n",
        "                'diariootro',\n",
        "                'ayerotro',\n",
        "                'promotro',\n",
        "                'diariootro1',\n",
        "                'ayerotro1',\n",
        "                'promotro1', \n",
        "                ]].reset_index()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {},
      "outputs": [],
      "source": [
        "prueba[\"capacidad\"]=\" \"\n",
        "prueba[\"ayer\"]=\" \"\n",
        "prueba[\"semana_pasada\"]=\" \"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Look up function\n",
        "\n",
        "def fillColumnWithLookup(df: DataFrame, values: list[tuple[str, str]], lookup_column: str, target_column:str):\n",
        "    \"\"\" \n",
        "    returns DataFrame with new columns filled with lookup parameters\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    df: DataFrame\n",
        "    values: list of 2-dimensional tuple. First is testing value.\n",
        "    Second is the output columns to which to place values that match the first.\n",
        "    lookup_column: a string of the field or column or dict property to which test the testing value\n",
        "    target_column: a string of a field or column or dict property to get the required value\n",
        "    \"\"\"\n",
        "    working_df = deepcopy(df)\n",
        "    for (value, output_column) in values:\n",
        "        working_df.loc[(working_df[lookup_column]== value), target_column] = working_df[output_column]\n",
        "    return working_df\n",
        "\n",
        "def processColumnFill(df: DataFrame, columnValues: list[dict]):\n",
        "    \"\"\" \n",
        "    returns DataFrame with new columns filled with lookup parameters\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    df: DataFrame\n",
        "    columnValues: list of Objects having:\n",
        "        values: list of 2-dimensional tuple. First is testing value.\n",
        "        Second is the output columns to which to place values that match the first.\n",
        "        lookup_column: a string of the field or column or dict property to which test the testing value\n",
        "        target_column: a string of a field or column or dict property to get the required value\n",
        "    \"\"\"\n",
        "    working_df = deepcopy(df)\n",
        "    for column in columnValues:\n",
        "        lookup_column = column[\"lookup_column\"]\n",
        "        target_column = column[\"target_column\"]\n",
        "        values = column[\"values\"]\n",
        "        working_df = fillColumnWithLookup(df=working_df, values=values, target_column=target_column, lookup_column=lookup_column)\n",
        "    return working_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {},
      "outputs": [],
      "source": [
        "diarValues = [\n",
        "    ('alimentacionynutricion', 'diarioalimentacionynutricion'),\n",
        "    ('alojamientotemporal', 'diarioalojamientotemporal'),\n",
        "    ('acompañamientoayudapsicosocial', 'diarioapoyooayudapsicosocial'),\n",
        "    ('aguapotable', 'diarioaguapotable'),\n",
        "    ('asesorialegal', 'diarioasesorialegal'),\n",
        "    ('educacion', 'diarioeducacion'),\n",
        "    ('higiene', 'diariohigiene'),\n",
        "    ('restablecimientodecontactofamiliar', 'diariorestablecimientodecontactofamiliar'),\n",
        "    ('saludprimerosauxiliosyatencionmedica', 'diariosaludprimerosauxiliosyatencionmedica'),\n",
        "    ('saneamiento', 'diariosaneamiento'),\n",
        "    ('serviciosdeproteccion', 'diarioserviciosproteccion'),\n",
        "    ('transferencias', 'diariotransferenciasmonetarias'),\n",
        "    ('transportehumanitario', 'diariotransportehumanitario'),\n",
        "    ('otro', 'diariootro'),\n",
        "]\n",
        "ayerValues = [\n",
        "    ('alimentacionynutricion', 'ayeralimentacionynutricion'),\n",
        "    ('alojamientotemporal', 'ayeralojamientotemporal'),\n",
        "    ('acompañamientoayudapsicosocial', 'ayerapoyooayudapsicosocial'),\n",
        "    ('aguapotable', 'ayeraguapotable'),\n",
        "    ('asesorialegal', 'ayerasesorialegal'),\n",
        "    ('educacion', 'ayereducacion'),\n",
        "    ('higiene', 'ayerhigiene'),\n",
        "    ('restablecimientodecontactofamiliar', 'ayerrestablecimientodecontactofamiliar'),\n",
        "    ('saludprimerosauxiliosyatencionmedica', 'ayersaludprimerosauxiliosyatencionmedica'),\n",
        "    ('saneamiento', 'ayersaneamiento'),\n",
        "    ('serviciosdeproteccion', 'ayerserviciosproteccion'),\n",
        "    ('transferencias', 'ayertransferenciasmonetarias'),\n",
        "    ('transportehumanitario', 'ayertransportehumanitario'),\n",
        "    ('otro', 'ayerotro'),\n",
        "]\n",
        "promValues = [\n",
        "    ('alimentacionynutricion', 'promalimentacionynutricion'),\n",
        "    ('alojamientotemporal', 'promalojamientotemporal'),\n",
        "    ('acompañamientoayudapsicosocial', 'promapoyooayudapsicosocial'),\n",
        "    ('aguapotable', 'promaguapotable'),\n",
        "    ('asesorialegal', 'promasesorialegal'),\n",
        "    ('educacion', 'promeducacion'),\n",
        "    ('higiene', 'promhigiene'),\n",
        "    ('restablecimientodecontactofamiliar', 'promrestablecimientodecontactofamiliar'),\n",
        "    ('saludprimerosauxiliosyatencionmedica', 'promsaludprimerosauxiliosyatencionmedica'),\n",
        "    ('saneamiento', 'promsaneamiento'),\n",
        "    ('serviciosdeproteccion', 'promserviciosproteccion'),\n",
        "    ('transferencias', 'promtransferenciasmonetarias'),\n",
        "    ('transportehumanitario', 'promtransportehumanitario'),\n",
        "    ('otro', 'promotro'),\n",
        "]\n",
        "\n",
        "\n",
        "columnValues = [\n",
        "    {\n",
        "        \"target_column\": \"capacidad\",\n",
        "        \"lookup_column\": \"servicios\",\n",
        "        \"values\": diarValues\n",
        "    },\n",
        "    {\n",
        "        \"target_column\": \"ayer\",\n",
        "        \"lookup_column\": \"servicios\",\n",
        "        \"values\": ayerValues\n",
        "    },\n",
        "    {\n",
        "        \"target_column\": \"semana_pasada\",\n",
        "        \"lookup_column\": \"servicios\",\n",
        "        \"values\": promValues\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {},
      "outputs": [],
      "source": [
        "prueba = processColumnFill(df=prueba, columnValues=columnValues)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {},
      "outputs": [],
      "source": [
        "newColumns = { '_uuid' : 'submission_id',\n",
        "               'servicios' : 'servicio',\n",
        "               'semana_pasada' : 'semana+anterior',\n",
        "               'ayer' : 'promedio+ayer',\n",
        "               '_coordenadas_latitude' : 'observation_lat',\n",
        "               '_coordenadas_longitude' : 'observation_lon',\n",
        "               'punto_reporte' : 'Región'\n",
        "               }\n",
        "\n",
        "prueba = prueba.rename(columns=newColumns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {},
      "outputs": [],
      "source": [
        "wide= prueba[[ 'submission_id',\n",
        "                 'servicio',\n",
        "                 'capacidad', \n",
        "                 'semana+anterior',\n",
        "                 'promedio+ayer',\n",
        "                 'observation_lat',\n",
        "                 'observation_lon',\n",
        "                 'Región',\n",
        "                 'organizacionprincipal', \n",
        "                 'organizacionimplementadora',\n",
        "                 \n",
        "                ]].reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {},
      "outputs": [],
      "source": [
        "wide1= wide.dropna(subset=['servicio']).reset_index(drop=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'serv_tipo'\n",
            "'cuenta_con'\n",
            "'cual_serv1'\n",
            "'cual_ser_2'\n",
            "'almacenamientoregistros'\n",
            "'financiamiento'\n",
            "'princ_reto'\n",
            "'idioma_ent'\n",
            "'medios_bri'\n",
            "data export to bd_serv_prem_wide.csv\n"
          ]
        }
      ],
      "source": [
        "output_df = processMultValueColumns(wide1, values)\n",
        "exportToFile(output_df, \"csv\", \"bd_serv_prem_wide\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
