{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 3, saw 4\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\maola\\Desktop\\Code\\Aurora.ipynb Cell 1\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/maola/Desktop/Code/Aurora.ipynb#W0sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m aurora_cara \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mAurora v2.1 data file - caracterización.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/maola/Desktop/Code/Aurora.ipynb#W0sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m aurora_feedback \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mAurora v2.1 data file - ayudaHumanitaria.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/maola/Desktop/Code/Aurora.ipynb#W0sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m aurora_monitoreo \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mAurora v2.1 data file - monitoreo.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/maola/Desktop/Code/Aurora.ipynb#W0sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m default_value \u001b[39m=\u001b[39m \u001b[39m999999\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\maola\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\maola\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\maola\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\maola\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n\u001b[0;32m    610\u001b[0m \u001b[39mwith\u001b[39;00m parser:\n\u001b[1;32m--> 611\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39mread(nrows)\n",
      "File \u001b[1;32mc:\\Users\\maola\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1778\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1771\u001b[0m nrows \u001b[39m=\u001b[39m validate_integer(\u001b[39m\"\u001b[39m\u001b[39mnrows\u001b[39m\u001b[39m\"\u001b[39m, nrows)\n\u001b[0;32m   1772\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1773\u001b[0m     \u001b[39m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m     (\n\u001b[0;32m   1775\u001b[0m         index,\n\u001b[0;32m   1776\u001b[0m         columns,\n\u001b[0;32m   1777\u001b[0m         col_dict,\n\u001b[1;32m-> 1778\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mread(  \u001b[39m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m   1779\u001b[0m         nrows\n\u001b[0;32m   1780\u001b[0m     )\n\u001b[0;32m   1781\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   1782\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\maola\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:230\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow_memory:\n\u001b[1;32m--> 230\u001b[0m         chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader\u001b[39m.\u001b[39mread_low_memory(nrows)\n\u001b[0;32m    231\u001b[0m         \u001b[39m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    232\u001b[0m         data \u001b[39m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32mc:\\Users\\maola\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:808\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\maola\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:866\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\maola\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:852\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\maola\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:1973\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 3, saw 4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from datetime import datetime\n",
    "from copy import deepcopy\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import fsspec\n",
    "import re\n",
    "\n",
    "from time import sleep\n",
    "\n",
    "# Mapbox\n",
    "from mapbox import Geocoder\n",
    "\n",
    "\n",
    "# Import dataset\n",
    "aurora_cara = pd.read_csv(\"Aurora v2.1 data file - caracterización.csv\")\n",
    "aurora_feedback = pd.read_csv(\"Aurora v2.1 data file - ayudaHumanitaria.csv\")\n",
    "aurora_monitoreo = pd.read_csv(\"Aurora v2.1 data file - monitoreo.csv\")\n",
    "\n",
    "default_value = 999999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "def loadLocalJsonDoc(filepath, dataProp=''):\n",
    "    \"\"\"\n",
    "    return deserialised json in dictionary\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filepath: file location or buffer.\n",
    "    dataProp: (optional) specified property to access required data\n",
    "    \"\"\"\n",
    "    output = {}\n",
    "    with open(file=filepath, mode='r', encoding='utf-8') as f:\n",
    "        json_load = json.load(f)\n",
    "        if (dataProp):\n",
    "            output = json_load[dataProp]\n",
    "        else:\n",
    "            output = json_load\n",
    "    return output\n",
    "\n",
    "\n",
    "def changeCountriesByExpression(country, valueDict: dict[str, str]):\n",
    "    output = \"\"\n",
    "    for key, value in valueDict.items():\n",
    "        match = re.match(r\"^\"+key+r\".$\", country)\n",
    "        if (match):\n",
    "            return value\n",
    "\n",
    "    return output if len(output) else country\n",
    "\n",
    "\n",
    "def processCountries(countries: list[str], valueDict: dict[str, str]):\n",
    "    output = []\n",
    "    for country in countries:\n",
    "        try:\n",
    "            new_country = changeCountriesByExpression(\n",
    "                country=country, valueDict=valueDict)\n",
    "            output.append(new_country)\n",
    "        except Exception as e:\n",
    "            output.append(default_value)\n",
    "    return output\n",
    "\n",
    "\n",
    "def getCountriesWithCoordinates(countries: list[str], geo_countries: gpd.GeoDataFrame):\n",
    "    output = {}\n",
    "    for country in countries:\n",
    "        try:\n",
    "            filtered_country = geo_countries[geo_countries[\"NAME\"].str.lower(\n",
    "            ) == country].reindex()\n",
    "            centroidValue = (filtered_country.centroid).iloc[0]\n",
    "            output[country] = {\"x\": centroidValue.x, \"y\": centroidValue.y}\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            output[country] = {\"x\": default_value, \"y\": default_value}\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def toUnixTimestamp(time, format: str = \"%d/%m/%Y\"):\n",
    "    start = datetime(1970, 1, 1)\n",
    "    target = datetime.strptime(time, format)\n",
    "    in_seconds = (target - start).total_seconds()\n",
    "    in_milliseconds = int(in_seconds) * 1000\n",
    "    return in_milliseconds\n",
    "\n",
    "\n",
    "def getCoordinate(value: str, side: str, valueDict: dict[str, tuple[int, int]], expressionDict: dict[str, str]):\n",
    "    try:\n",
    "        country = changeCountriesByExpression(value, expressionDict)\n",
    "        return valueDict[country][side]\n",
    "    except Exception as e:\n",
    "        return default_value\n",
    "\n",
    "\n",
    "def processFieldCoordinates(df: pd.DataFrame, columnDict: dict[str, dict[str, str]], valueDict: dict[str, tuple[int, int]], expressionDict: dict[str, str]):\n",
    "    local_df = deepcopy(df)\n",
    "    for column in columnDict.keys():\n",
    "        local_df[columnDict[column][\"x\"]] = local_df[column].str.lower().apply(\n",
    "            lambda x: getCoordinate(x, \"x\", valueDict, expressionDict))\n",
    "        local_df[columnDict[column][\"y\"]] = local_df[column].str.lower().apply(\n",
    "            lambda x: getCoordinate(x, \"y\", valueDict, expressionDict))\n",
    "\n",
    "    return local_df\n",
    "\n",
    "def processGeocodeData(data):\n",
    "    features = data['features']\n",
    "    for feature in features:\n",
    "        id: str = feature['id']\n",
    "        match = id.startswith(\"country\")\n",
    "        if (match):\n",
    "            return (feature['properties']['short_code'], feature[\"place_name\"])\n",
    "\n",
    "    return \"zz\"\n",
    "\n",
    "\n",
    "def getMapboxGeocoder(token:str):\n",
    "    if(token):\n",
    "        return Geocoder(access_token=token)\n",
    "    else: \n",
    "        raise Exception(\"Invalid Token\")\n",
    "\n",
    "def reverseGeocode(longitude: int, latitude: int, token: str):\n",
    "    mb_geocoder = getMapboxGeocoder(token)\n",
    "    response = mb_geocoder.reverse(lat=latitude, lon=longitude)\n",
    "    if (response.status_code == 200):\n",
    "        data = response.json()\n",
    "        return data\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def processReverseGeoding(data: list[tuple[int, int]], token:str):\n",
    "    output = []\n",
    "    for lon, lat in data:\n",
    "        try:\n",
    "            result = reverseGeocode(lon, lat, token)\n",
    "            _decoded = processGeocodeData(result)\n",
    "            output.append(_decoded)\n",
    "            sleep(1)\n",
    "        except:\n",
    "            output.append((\"zz\", \"\"))\n",
    "\n",
    "    return output\n",
    "\n",
    "def addReverseGeocodedToDataFrame(df: DataFrame, token:str  ):\n",
    "    local_df = deepcopy(df)\n",
    "    coordinates = list(zip(list(local_df['longitude'].astype(float).to_list()), list(\n",
    "    local_df['latitude'].astype(float).to_list())))\n",
    "    reversed_geocoded_df = processReverseGeoding(coordinates,token)\n",
    "    local_df[\"country_code\"] = [x[0] for x in reversed_geocoded_df]\n",
    "    local_df[\"country_name\"] = [x[1] for x in reversed_geocoded_df]\n",
    "    return local_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "aurora = pd.merge(aurora_cara, aurora_feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop observations of Aurora team phones, test registers and geographical atypical rows \n",
    "\n",
    "\n",
    "user_ids_to_remove = [311571598, 311398466, 311396734, 311361421, 311361350, 311361257, 311337494, 311325070,\n",
    "                      311325038, 311272934, 310820267, 310543580, 310357249, 310191611, 308421831, 306028996,\n",
    "                      310191611, 308421831, 306028996, 311725039, 311719001, 311718121, 311699383, 311696700,\n",
    "                      312179120, 311965863, 311965863, 316773170, 311440316, 313260546, 316563135, 316734459,\n",
    "                      317064115]\n",
    "\n",
    "for user_id in user_ids_to_remove:\n",
    "    aurora = aurora.drop(aurora[aurora.UserId == user_id].index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "aurora=aurora[aurora['Consentimiento'] != 'NO'] \n",
    "aurora=aurora[aurora['¿Cómo interactúa con el sistema?'] != 'QR-Enganche'] \n",
    "aurora=aurora[aurora['Latitud'] != \"None\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename variables \n",
    "newColumns = {  'UserId' : 'objectid',\n",
    "                'Edad'\t: 'e06_edad',\n",
    "                'Género' :\t'e07_gener',\n",
    "                'Latitud' : 'lat',\n",
    "                'Longitud' : 'lon',\n",
    "                \"¿En qué país naciste?\" : 'e08_pais_',\n",
    "                'Otro país de nacimiento'\t: 'e09_otro_p',\n",
    "                '¿En qué país iniciaste tu viaje actual?'\t: 'e10_pais_',\n",
    "                'Otro país de inicio'\t: 'e11_otro_p',\n",
    "                '¿En qué país vivías hace un año?'\t : 'e12_pais_',\n",
    "                'Otro país'\t: 'e13_otro_p',\n",
    "                'Restringir una o más raciones de alimentos' :\t'e15__has_',\n",
    "                'Dormir a la intemperie' :\t'e16__tu_',\n",
    "                'Ha necesitado asistencia médica' : 'asistencia_medica',\n",
    "                '¿Cuántas personas te acompañan en tu viaje?' :\t'e17__cua',\n",
    "                'Hay niños, niñas o adolescentes'\t : 'e18__entr',\n",
    "                'Total NNA'\t: 'e19_cu',\n",
    "                'NNA de 0 a 5' :\t'e20__cua',\n",
    "                'NNA de 6 a 11' :\t'e21__cua',\n",
    "                'NNA de 12 a 17'\t: 'e22__cua',\n",
    "                'Lugar interacción'\t: 'e24__me_c',\n",
    "                'Mujer embarazo viajando' : 'm01__en_t',\n",
    "                'Mujer lactando viajando' : 'lactante',\n",
    "                'Tienes alguna enfermedad crónica'\t: 'm02__en_t',\n",
    "                'Tienes alguna condición de discapacidad'\t: 'm03__dent',\n",
    "                'Cuáles han sido tus 3 principales necesidades': 'necesidades', \n",
    "                '¿Recibiste ayuda humanitaria en el lugar actual?' : 'm09__acce',\n",
    "                'Cual ayuda humanitaria' :\t'm12__cua',       \n",
    "                'Qué tan fácil fue acceder a la ayuda' :\t'm14_respec',\n",
    "                'Qué tan satisfecho te sientes respecto a la ayuda' : 'm15__que',\n",
    "               'Recomendarías la ayuda ' : 'm16_de_acu',\n",
    "               'Cual ayuda humanitaria NNA' :\t'm18_me_con',      \n",
    "               'NNA: Qué tan fácil fue acceder a la ayuda' : 'm19_respec',\n",
    "               'NNA: Qué tan satisfecho te sientes respecto a la ayuda' :\t'm20__que',\n",
    "               'NNA: Recomendarías la ayuda' : 'm21_de_acu',\n",
    "\n",
    "}\n",
    "\n",
    "aurora_carto = aurora.rename(columns=newColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single positional indexer is out-of-bounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maola\\AppData\\Local\\Temp\\ipykernel_8664\\394413194.py:49: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  centroidValue = (filtered_country.centroid).iloc[0]\n"
     ]
    }
   ],
   "source": [
    "available_countries = [x.lower() for x in list(set(list(aurora_carto[\"e08_pais_\"].unique(\n",
    ")) + list(aurora_carto[\"e10_pais_\"].unique()) + list(aurora_carto[\"e12_pais_\"].unique()))) if type(x) == str]\n",
    "\n",
    "countries_dict = loadLocalJsonDoc(\"defaults/countries_dict.json\")\n",
    "\n",
    "available_countries = processCountries(available_countries, countries_dict)\n",
    "\n",
    "# adding coordinates value\n",
    "country_data_path = \"simplecache::https://www.naturalearthdata.com/http//www.naturalearthdata.com/download/110m/cultural/ne_110m_admin_0_countries.zip\"\n",
    "\n",
    "country_df = \"\"\n",
    "\n",
    "with fsspec.open(country_data_path) as file:\n",
    "    country_df = gpd.read_file(file)\n",
    "\n",
    "countriesWithCoordinates = getCountriesWithCoordinates(\n",
    "    available_countries, country_df)\n",
    "country_column_dict = loadLocalJsonDoc(\"defaults/country_column_dict.json\")\n",
    "aurora_carto = processFieldCoordinates(\n",
    "    aurora_carto, country_column_dict, countriesWithCoordinates, countries_dict)\n",
    "aurora_carto['lon_eng'] = aurora_carto['lon']\n",
    "aurora_carto['lat_eng'] = aurora_carto['lat']\n",
    "aurora_carto['longitude'] = aurora_carto['lon']\n",
    "aurora_carto['latitude'] = aurora_carto['lat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the variable time\n",
    "# the format was missing other elements thus the timestring was not parsing\n",
    "aurora_carto[\"timeunix\"] = aurora_carto[\"Inicio interacción\"].apply(lambda x: toUnixTimestamp(x, '%Y-%m-%d %H:%M:%S.%f+00:00'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPBOX_TOKEN = os.environ.get(\"MAPBOX_TOKEN\")\n",
    "# This is heavy process that takes a while to finish\n",
    "# should be used sparingly and closer to end processes.\n",
    "aurora_carto = addReverseGeocodedToDataFrame(aurora_carto, MAPBOX_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling missing values\n",
    "# should be done at the very end\n",
    "aurora_carto = aurora_carto.fillna(default_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#database for Carto\n",
    "aurora_carto.to_csv('aurora_round_2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
